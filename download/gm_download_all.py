# download/gm_download_all.py
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€çš„æ˜é‡‘æ•°æ®ä¸‹è½½æ¨¡å—ï¼š
- Aè‚¡ä¸ªè‚¡ / æŒ‡æ•°æ—¥çº¿
- è‚¡æŒ‡æœŸè´§æ—¥çº¿

è¾“å‡ºç»Ÿä¸€ä¸º CSVï¼Œæ ¼å¼ï¼š
    date, open, high, low, close, volume

ä¾èµ–ï¼š
    pip install gm.api pandas

é…ç½®ï¼š
    åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ config/config.py ä¸­é…ç½® GM_TOKENï¼Œä¾‹å¦‚ï¼š
        GM_TOKEN = "ä½ çš„token"
"""

from __future__ import annotations

import os
import sys
import re
from datetime import datetime,timedelta
from pathlib import Path
from typing import Optional

import pandas as pd
from gm.api import *

import numpy as np

# ========= è®© Python èƒ½æ‰¾åˆ° config åŒ… =========
ROOT_DIR = Path(__file__).resolve().parents[1]   # é¡¹ç›®æ ¹ç›®å½•
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

from config.config import GM_TOKEN  # ä½ çš„æ˜é‡‘ token
from common import ensure_utf8_filename


# ========= å…¬å…±å·¥å…·å‡½æ•° =========

def init_gm() -> None:
    """åˆå§‹åŒ–æ˜é‡‘ SDK"""
    if not GM_TOKEN:
        raise RuntimeError("è¯·å…ˆåœ¨ config/config.py é‡Œè®¾ç½® GM_TOKEN")
    set_token(GM_TOKEN)


def sanitize_name_for_filename(name: str) -> str:
    """
    æŠŠä¸­æ–‡å / è‹±æ–‡åå˜æˆé€‚åˆæ–‡ä»¶åçš„å½¢å¼ï¼š
    - å»æ‰å‰åç©ºæ ¼
    - å»æ‰ç©ºæ ¼
    - å»æ‰ä¸é€‚åˆæ–‡ä»¶åçš„ç¬¦å· / \ : * ? " < > |
    """
    name = (name or "").strip()
    name = name.replace(" ", "")
    name = re.sub(r'[\\/:*?"<>|]', "", name)
    return ensure_utf8_filename(name or "UNKNOWN")


def normalize_symbol(code: str, market: Optional[str] = None) -> str:
    code = code.strip().upper()
    if "." in code:
        return code

    if market is not None:
        m = market.upper()
        # â­ æ”¯æŒ SHã€SHSEã€SHSZ éƒ½å½“æˆä¸Šäº¤æ‰€
        if m in ("SH", "SHSE", "SHSZ"):
            prefix = "SHSE"
        elif m in ("SZ", "SZSE"):
            prefix = "SZSE"
        else:
            raise ValueError(f"æ— æ³•è¯†åˆ«çš„ market: {market}")
    else:
        prefix = "SHSE" if code.startswith(("5", "6", "9")) else "SZSE"

    return f"{prefix}.{code}"



def get_symbol_cn_name(symbol: str) -> str:
    """
    ä»æ˜é‡‘æ‹¿ sec_nameï¼ˆé€‚ç”¨äºè‚¡ç¥¨ã€æŒ‡æ•°ã€æœŸè´§ç­‰ï¼Œåªè¦åœ¨ get_instruments é‡Œèƒ½æŸ¥åˆ°ï¼‰
    symbol å½¢å¦‚ "SHSE.600519" / "CFFEX.IF2501"
    """
    inst_df = get_instruments(symbols=symbol, df=True)
    if inst_df is None or inst_df.empty:
        return "UNKNOWN"
    raw_name = str(inst_df.iloc[0].get("sec_name", "") or "")
    return sanitize_name_for_filename(raw_name)


# ========= ä¸ªè‚¡ / æŒ‡æ•° æ—¥çº¿ =========
def update_daily_equity(
    code: str,
    start_date: str = "2005-01-01",
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_equity",
    market: Optional[str] = None,
) -> str:
    """
    å¢é‡æ›´æ–°å•åª A è‚¡ / æŒ‡æ•°çš„æ—¥çº¿æ•°æ®ï¼ˆåŸºäºå·²æœ‰ CSV è¡¥åˆ°æœ€æ–°ï¼‰

    é€»è¾‘ï¼š
    1ï¼‰åœ¨ out_dir é‡ŒæŒ‰ code å‰ç¼€æ‰¾å†å²æ–‡ä»¶ï¼š
        000001_å¹³å®‰é“¶è¡Œ_D_qfq_gm.csv
        000001_å¹³å®‰é“¶è¡Œ_D_gm.csv
        000001_*.csv
    2ï¼‰è¯»å‡ºå†å²æ–‡ä»¶ï¼Œå–æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ last_dt
    3ï¼‰ä» max(start_date, last_dt+1) å¼€å§‹ï¼Œç”¨ gm.history æ‹‰å–å¢é‡æ•°æ®
    4ï¼‰æ–°æ•°æ®æŒ‰æ—§æ–‡ä»¶çš„åˆ—é¡ºåºå¯¹é½åï¼Œ**ç›´æ¥åœ¨åŸæ–‡ä»¶å°¾éƒ¨è¿½åŠ **ï¼Œä¸æ”¹æ—§æ•°æ®

    è¿”å›ï¼š
        æœ€ç»ˆå†™å›/ç”Ÿæˆçš„ CSV è·¯å¾„
    """
    init_gm()

    # ç»“æŸæ—¥æœŸï¼šé»˜è®¤ä»Šå¤©
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")
    end_d = datetime.strptime(end_date, "%Y-%m-%d").date()

    # è¾“å‡ºç›®å½•
    out_dir_path = Path(out_dir)
    out_dir_path.mkdir(parents=True, exist_ok=True)

    # ========= 1. æ‰¾å·²æœ‰æ–‡ä»¶ï¼ˆå…¼å®¹ *_D_qfq_gm / *_D_gm / å…¶ä»–å‰ç¼€ï¼‰ =========
    patterns = [
        f"{code}_*_D_qfq_gm*.csv",
        f"{code}_*_D_gm*.csv",
        f"{code}_*.csv",   # å…œåº•ï¼šåªè¦å‰ç¼€æ˜¯ code çš„éƒ½è®¤
    ]

    existing_files: list[Path] = []
    for pat in patterns:
        files = sorted(out_dir_path.glob(pat))
        if files:
            existing_files = files
            break

    # ========= 2. å¦‚æœæ²¡æœ‰å†å²æ–‡ä»¶ï¼Œé€€å›â€œå…¨é‡ä¸‹è½½â€ =========
    if not existing_files:
        print(f"â„¹ï¸ æœªæ‰¾åˆ° {code} çš„å†å²æ—¥çº¿æ–‡ä»¶ï¼Œå°†ä» {start_date} å…¨é‡ä¸‹è½½")
        return download_daily_equity(
            code=code,
            start_date=start_date,
            end_date=end_date,
            out_dir=out_dir,
            market=market,
        )

    # å–æœ€æ–°çš„é‚£ä¸€ä¸ªæ–‡ä»¶ï¼ˆæ–‡ä»¶åæ’åºåæœ€åä¸€ä¸ªï¼‰
    csv_path = existing_files[-1]
    print(f"âœ… æ‰¾åˆ°å·²æœ‰æ–‡ä»¶: {csv_path}")

    df_old = pd.read_csv(csv_path)

    # å°è¯•è¯†åˆ«æ—¶é—´åˆ—ï¼šä¼˜å…ˆ eobï¼Œæ²¡æœ‰åˆ™ç”¨ dateï¼ˆå…¼å®¹ä½ ä»¥å‰çš„ D_gm æ–‡ä»¶ï¼‰
    if "eob" in df_old.columns:
        dt_series = pd.to_datetime(df_old["eob"])
        time_col = "eob"
    elif "date" in df_old.columns:
        dt_series = pd.to_datetime(df_old["date"])
        time_col = "date"
    else:
        raise ValueError(
            f"{csv_path} æ—¢æ²¡æœ‰ 'eob' ä¹Ÿæ²¡æœ‰ 'date' åˆ—ï¼Œæ— æ³•åšå¢é‡æ›´æ–°"
        )

    last_dt = dt_series.max().date()
    print(f"ğŸ“Œ {code} æœ¬åœ°æœ€åäº¤æ˜“æ—¥: {last_dt}")

    # ç”¨æˆ·è¦æ±‚çš„æœ€æ—©èµ·å§‹æ—¥
    user_start = datetime.strptime(start_date, "%Y-%m-%d").date()
    # å¢é‡çœŸæ­£èµ·ç‚¹ï¼šlast_dt + 1 å’Œ user_start å–è¾ƒæ™šè€…
    incr_start_d = max(user_start, last_dt + timedelta(days=1))

    if incr_start_d > end_d:
        print(f"âœ… {code} æ—¥çº¿å·²æ›´æ–°åˆ° {last_dt}ï¼Œæ— éœ€å¢é‡ä¸‹è½½")
        return str(csv_path)

    incr_start = incr_start_d.strftime("%Y-%m-%d")
    print(f"ğŸ“¡ å‡†å¤‡å¢é‡ä¸‹è½½ {code} æ—¥çº¿: {incr_start} ~ {end_date}")

    # ========= 3. è°ƒ gm.history æ‹‰å¢é‡ =========
    symbol = normalize_symbol(code, market=market)

    start_time = incr_start + " 09:30:00"
    end_time = end_date + " 15:00:00"

    df_new = history(
        symbol=symbol,
        frequency="1d",
        start_time=start_time,
        end_time=end_time,
        # â­ ä¸ºäº†è·Ÿä¹‹å‰æ–‡ä»¶ä¸€è‡´ï¼Œç»§ç»­ç”¨è¿™å‡ ä¸ªå­—æ®µ
        fields="eob,open,high,low,close,volume",
        df=True,
        # ä¸å† fill_missingï¼Œä¸åšæœ¬åœ°æ’å€¼
        # fill_missing="last",
    )

    if df_new is None or df_new.empty:
        print(f"âš ï¸ {code} åœ¨ {incr_start}~{end_date} æ²¡æœ‰æ–°æ•°æ®ï¼Œæœ¬åœ°å·²æœ€æ–°")
        return str(csv_path)

    print(f"âœ… æ–°å¢ {len(df_new)} è¡Œ")

    # ========= 4. å¯¹é½åˆ—ï¼Œç„¶ååœ¨åŸæ–‡ä»¶å°¾éƒ¨è¿½åŠ  =========
    df_new = df_new.copy()

    old_cols = list(df_old.columns)

    # å…ˆè¡¥é½æ–°è¡¨ä¸­ç¼ºå°‘çš„æ—§åˆ—ï¼ˆå¡« NAï¼‰ï¼Œä¿è¯åˆ—é½å…¨
    for c in old_cols:
        if c not in df_new.columns:
            df_new[c] = pd.NA

    # å¦‚æœæ–°æ•°æ®é‡Œæœ‰æ—§æ–‡ä»¶æ²¡æœ‰çš„åˆ—ï¼Œä¸ºäº†ä¸ç ´åè€æ–‡ä»¶ç»“æ„ï¼Œå¯ä»¥ä¸¢å¼ƒè¿™äº›åˆ—
    extra_cols = [c for c in df_new.columns if c not in old_cols]
    if extra_cols:
        df_new = df_new.drop(columns=extra_cols)

    # æŒ‰æ—§æ–‡ä»¶çš„åˆ—é¡ºåºé‡æ’
    df_new = df_new[old_cols]

    # ç¡®ä¿æ—¶é—´åˆ—æ˜¯ datetimeï¼ˆè™½ç„¶è¿™é‡Œåª appendï¼Œä¸å»é‡ï¼Œè¿˜æ˜¯ä¹ æƒ¯ç»Ÿä¸€ä¸€ä¸‹ï¼‰
    df_new[time_col] = pd.to_datetime(df_new[time_col])

    # â­ å…³é”®ï¼šä¸æ”¹æ—§æ•°æ®ï¼Œåªåœ¨æ–‡ä»¶å°¾éƒ¨è¿½åŠ æ–°è¡Œï¼Œä¸å†™è¡¨å¤´
    df_new.to_csv(
        csv_path,
        mode="a",
        index=False,
        header=False,
        encoding="utf-8-sig",
    )

    print(f"ğŸ’¾ {code} æ—¥çº¿å·²åœ¨åŸæ–‡ä»¶å°¾éƒ¨è¿½åŠ  {len(df_new)} è¡Œ: {csv_path}")
    return str(csv_path)

def update_daily_equity_file(
    csv_path: Path,
    start_date: str = "2005-01-01",
    end_date: Optional[str] = None,
    market: Optional[str] = None,
) -> str:
    """
    é’ˆå¯¹â€œæŒ‡å®šçš„æŸä¸€ä¸ª CSV æ–‡ä»¶â€åšæ—¥çº¿å¢é‡æ›´æ–°ï¼š
    - ä¿ç•™åŸè·¯å¾„ã€åŸæ–‡ä»¶åä¸å˜
    - åªåœ¨åŸæ–‡ä»¶å°¾éƒ¨è¿½åŠ æ–°æ•°æ®ï¼ˆä¸è¦†ç›–æ—§æ•°æ®ï¼‰

    å‘½åçº¦å®šï¼ˆä¸æ”¹ä½ ä¹‹å‰çš„è§„åˆ™ï¼‰ï¼š
        000001_å¹³å®‰é“¶è¡Œ_D_qfq_gm.csv  ç­‰
        code_åå­—_é¢‘ç‡_...csv

    é€»è¾‘ï¼š
    1ï¼‰ä»æ–‡ä»¶åæå– code
    2ï¼‰è¯»å–æ—§æ•°æ®ï¼Œæ‰¾åˆ°æœ€åäº¤æ˜“æ—¥ last_dt
    3ï¼‰ä» max(start_date, last_dt + 1) å¼€å§‹è°ƒ gm.history
    4ï¼‰å¯¹é½åˆ—é¡ºåºï¼ŒåªæŠŠæ–°è¡Œè¿½åŠ åˆ°åŸ CSV å°¾éƒ¨
    """
    init_gm()

    csv_path = Path(csv_path)
    if not csv_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {csv_path}")

    # === ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä»Šå¤© ===
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")
    end_d = datetime.strptime(end_date, "%Y-%m-%d").date()

    # === 1. ä»æ–‡ä»¶åæå– code ===
    code = extract_code_from_filename(csv_path)
    symbol = normalize_symbol(code, market=market)

    print(f"ğŸ” æ­£åœ¨æ£€æŸ¥ {csv_path.name} ({symbol}) æ˜¯å¦éœ€è¦å¢é‡æ›´æ–°...")

    # === 2. è¯»å–æ—§æ•°æ®ï¼Œæ‰¾æœ€åäº¤æ˜“æ—¥ ===
    df_old = pd.read_csv(csv_path)
    if df_old.empty:
        # ç©ºæ–‡ä»¶å°±å½“æ²¡æœ‰å†å²ï¼Œç›´æ¥å…¨é‡ä¸‹è½½åˆ°è¿™ä¸ªæ–‡ä»¶ï¼ˆè¦†ç›–ï¼‰
        print(f"âš ï¸ {csv_path} æ˜¯ç©ºæ–‡ä»¶ï¼Œå°†ä» {start_date} å…¨é‡ä¸‹è½½å¹¶è¦†ç›–")
        return download_daily_equity(
            code=code,
            start_date=start_date,
            end_date=end_date,
            out_dir=str(csv_path.parent),
            market=market,
        )

    if "eob" in df_old.columns:
        time_col = "eob"
        dt_series = pd.to_datetime(df_old["eob"])
    elif "date" in df_old.columns:
        time_col = "date"
        dt_series = pd.to_datetime(df_old["date"])
    else:
        raise ValueError(f"{csv_path} æ—¢æ²¡æœ‰ 'eob' ä¹Ÿæ²¡æœ‰ 'date' åˆ—ï¼Œæ— æ³•å¢é‡æ›´æ–°")

    last_dt = dt_series.max().date()
    print(f"ğŸ“Œ å½“å‰æ–‡ä»¶æœ€åäº¤æ˜“æ—¥: {last_dt}")

    user_start = datetime.strptime(start_date, "%Y-%m-%d").date()
    incr_start_d = max(user_start, last_dt + timedelta(days=1))

    if incr_start_d > end_d:
        print(f"âœ… {csv_path.name} å·²æ›´æ–°è‡³ {last_dt}ï¼Œæ— éœ€å¢é‡ä¸‹è½½")
        return str(csv_path)

    incr_start = incr_start_d.strftime("%Y-%m-%d")
    print(f"ğŸ“¡ å‡†å¤‡å¢é‡ä¸‹è½½ {symbol} æ—¥çº¿: {incr_start} ~ {end_date}")

    # === 3. è°ƒ gm.history æ‹‰å¢é‡ ===
    start_time = incr_start + " 09:30:00"
    end_time = end_date + " 15:00:00"

    df_new = history(
        symbol=symbol,
        frequency="1d",
        start_time=start_time,
        end_time=end_time,
        # ä¿æŒâ€œåŸå§‹å­—æ®µâ€é£æ ¼
        fields="eob,open,high,low,close,volume",
        adjust=ADJUST_PREV,
        df=True,
    )

    if df_new is None or df_new.empty:
        print(f"âš ï¸ {symbol} åœ¨ {incr_start}~{end_date} æ²¡æœ‰æ–°å¢æ—¥çº¿æ•°æ®")
        return str(csv_path)

    print(f"âœ… æ–°å¢ {len(df_new)} è¡Œï¼Œå°†åœ¨åŸæ–‡ä»¶å°¾éƒ¨è¿½åŠ ")

    df_new = df_new.copy()

    # === 4. å¯¹é½åˆ—ï¼šåªä¿è¯â€œæ–°æ•°æ®åˆ— âŠ‡ æ—§æ–‡ä»¶åˆ—â€ï¼Œå¤šä½™åˆ—ä¸¢å¼ƒ ===
    old_cols = list(df_old.columns)

    # å¦‚æœæ—§æ–‡ä»¶ç”¨çš„æ˜¯ 'date'ï¼Œè€Œæ–°æ•°æ®åªæœ‰ 'eob'ï¼Œè¿™é‡Œåšä¸ªå…¼å®¹è½¬æ¢
    if ("date" in old_cols) and ("eob" in df_new.columns) and ("date" not in df_new.columns):
        df_new["date"] = pd.to_datetime(df_new["eob"]).dt.strftime("%Y-%m-%d")

    # è¡¥é½æ—§æ–‡ä»¶é‡Œæœ‰ä½†æ–°æ•°æ®é‡Œç¼ºå°‘çš„åˆ—
    for c in old_cols:
        if c not in df_new.columns:
            df_new[c] = pd.NA

    # åªä¿ç•™æ—§æ–‡ä»¶çš„åˆ—é¡ºåºï¼Œä¿è¯æ ¼å¼å®Œå…¨ä¸€è‡´
    df_new = df_new[old_cols]

    # === 5. è¿½åŠ å†™å›ï¼šä¸è¦†ç›–æ—§å†…å®¹ ===
    df_new.to_csv(
        csv_path,
        mode="a",           # è¿½åŠ 
        index=False,
        header=False,       # ä¸é‡å¤å†™è¡¨å¤´
        encoding="utf-8-sig",
    )
    print(f"ğŸ’¾ å·²å‘ {csv_path.name} è¿½åŠ  {len(df_new)} è¡Œ")
    return str(csv_path)


def batch_download_equity_from_csv(
    data_dirs: list[str],
    start_date: str = "2005-01-01",   # ä»…åœ¨æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼Œç”¨äºå…¨é‡ä¸‹è½½çš„èµ·å§‹æ—¥
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_equity",
) -> None:
    """
    ï¼ˆå·²æ”¹é€ ï¼‰
    ä¸å†ä» config CSV è¯»å–è‚¡ç¥¨æ± ï¼Œè€Œæ˜¯ä»ç»™å®šçš„æ•°æ®ç›®å½•é›†åˆä¸­ï¼š
        - æ‰«æå·²ä¿å­˜çš„æ—¥çº¿ / åˆ†é’Ÿçº¿ CSV æ–‡ä»¶
        - æŒ‰æ–‡ä»¶åæŠ½å– codeï¼ˆä¾‹å¦‚ 600519_*.csv â†’ code = 600519ï¼‰
        - å¯¹è¿™äº› code è°ƒç”¨ update_daily_equity åšâ€œæ—¥çº¿å¢é‡æ›´æ–°â€

    å‚æ•°ï¼š
        data_dirs: ç›®å½•åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š
            ["./data/gm_equity", "./data/gm_equity_intraday"]
            æ—¢å¯ä»¥åªç»™æ—¥çº¿ç›®å½•ï¼Œä¹Ÿå¯ä»¥æŠŠåˆ†é’Ÿçº¿ç›®å½•ä¸€èµ·ä¸¢è¿›æ¥ï¼Œ
            æˆ‘ä»¬åªæ˜¯ç”¨æ–‡ä»¶åæå– codeã€‚
        start_date: å¦‚æœæŸä¸ª code è¿˜æ²¡æœ‰ä»»ä½•æ—¥çº¿æ–‡ä»¶æ—¶ï¼Œ
                    ä¼šé€€åŒ–ä¸ºä¸€æ¬¡å®Œæ•´ä¸‹è½½ï¼Œç”¨è¿™ä¸ªèµ·å§‹æ—¶é—´ã€‚
        end_date:   ä¸‹è½½æˆªæ­¢æ—¥æœŸï¼ŒNone = æˆªæ­¢åˆ°ä»Šå¤©
        out_dir:    æ—¥çº¿ CSV æ‰€åœ¨ç›®å½•ï¼ˆå¢é‡æ›´æ–°ç›®æ ‡ç›®å½•ï¼‰
    """
    init_gm()

    codes = collect_codes_from_dirs(data_dirs)
    if not codes:
        print("âš ï¸ åœ¨æŒ‡å®šç›®å½•ä¸­æ²¡æœ‰å‘ç°ä»»ä½• CSV æ–‡ä»¶ï¼Œæˆ–æ— æ³•æå–ä»£ç ")
        return

    print(f"ğŸ“ƒ å…±è¯†åˆ«åˆ° {len(codes)} åªæ ‡çš„: {', '.join(codes)}")

    for i, code in enumerate(codes, start=1):
        print(f"\n==== [Equity UPDATE {i}/{len(codes)}] è¡¥å…… {code} æ—¥çº¿ ====")
        try:
            # update_daily_equity å†…éƒ¨é€»è¾‘ï¼š
            # - è‹¥å·²æœ‰æ—¥çº¿æ–‡ä»¶ï¼šä»æ–‡ä»¶æœ€åä¸€å¤© + 1 å¼€å§‹è¡¥
            # - è‹¥æ²¡æœ‰ï¼šè°ƒç”¨ download_daily_equity åšä¸€æ¬¡å®Œæ•´ä¸‹è½½
            update_daily_equity(
                code=code,
                start_date=start_date,
                end_date=end_date,
                out_dir=out_dir,
                market=None,
            )
        except Exception as e:
            print(f"âŒ {code} æ—¥çº¿è¡¥å……å¤±è´¥: {e}")


def download_daily_equity(
    code: str,
    start_date: str = "2005-01-01",
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_equity",
    market: Optional[str] = None,
    adjust=ADJUST_PREV,      # â­ ä¾ç„¶é»˜è®¤å‰å¤æƒï¼ˆè¿™æ˜¯è¯·æ±‚å‚æ•°ï¼Œä¸ç®—â€œåå¤„ç†â€ï¼‰
) -> str:
    """
    ä¸‹è½½å•åª A è‚¡ / æŒ‡æ•°çš„æ—¥çº¿æ•°æ®ï¼ˆåŸå§‹æ˜é‡‘å­—æ®µåŸæ ·ä¿å­˜ï¼‰

    å‚æ•°ï¼š
        code:   "600519" / "000300" / "SHSE.000300"
        start_date: "YYYY-MM-DD"
        end_date:   "YYYY-MM-DD"ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        out_dir:    è¾“å‡ºç›®å½•
        market:     å¯é€‰ "SH"/"SZ"
        adjust:     å¤æƒæ–¹å¼ï¼Œé»˜è®¤ ADJUST_PREVï¼ˆå‰å¤æƒï¼‰
    """
    init_gm()

    symbol = normalize_symbol(code, market=market)
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")

    start_time = start_date + " 09:30:00"
    end_time = end_date + " 15:00:00"

    print(f"ğŸ“¡ ä¸‹è½½ {symbol} æ—¥çº¿(å‰å¤æƒ): {start_date} ~ {end_date}")

    df = history(
        symbol=symbol,
        frequency="1d",
        start_time=start_time,
        end_time=end_time,
        fields="eob,open,high,low,close,volume",
        adjust=adjust,      # â­ è¿™é‡Œè¿˜æ˜¯å‰å¤æƒ
        df=True,
        # âŒ ä¸å† fill_missingï¼Œä¸å†åšä»»ä½•æœ¬åœ°åŠ å·¥
        # fill_missing="last",
    )

    if df is None or df.empty:
        raise RuntimeError(f"{symbol} åœ¨ {start_date}~{end_date} æ²¡æœ‰æ‹¿åˆ°æ•°æ®")

    os.makedirs(out_dir, exist_ok=True)

    raw_code = symbol.split(".")[-1]     # 600519 / 000300
    cn_name = ensure_utf8_filename(get_symbol_cn_name(symbol))  # è´µå·èŒ…å° / æ²ªæ·±300

    # åå­—ä½ å¯ä»¥æŒ‰å–œå¥½æ¥ï¼Œæˆ‘è¿™é‡Œä»ç„¶æ ‡è®° qfq_gm æ–¹ä¾¿ä»¥åè¯†åˆ«
    file_name = ensure_utf8_filename(f"{raw_code}_{cn_name}_D_qfq_gm.csv")
    out_path = ensure_utf8_filename(os.path.join(out_dir, file_name))

    # â­ å…³é”®ï¼šç›´æ¥æŠŠæ˜é‡‘çš„ df åŸæ ·è½ç›˜
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ä¿å­˜åˆ°: {out_path}, å…± {len(df)} è¡Œ")
    return out_path

def download_intraday_equity(
    code: str,
    frequency: str = "60s",          # â­ é»˜è®¤ 1 åˆ†é’Ÿ
    start_date: str = "2020-01-01",
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_intraday",
    market: Optional[str] = None,
    adjust=ADJUST_PREV,              # â­ ä»ç„¶æ˜¯å‰å¤æƒ
) -> str:
    """
    ä¸‹è½½å•åª A è‚¡ / æŒ‡æ•°çš„åˆ†é’Ÿçº¿æ•°æ®ï¼ˆåŸå§‹æ˜é‡‘å­—æ®µåŸæ ·ä¿å­˜ï¼‰

    å‚æ•°ï¼š
        code:       "600519" / "000300" / "SHSE.000300"
        frequency:  "60s"ã€"300s" ç­‰
        start_date: "YYYY-MM-DD"
        end_date:   "YYYY-MM-DD"
        out_dir:    è¾“å‡ºç›®å½•
        market:     å¯é€‰ "SH"/"SZ"
        adjust:     å¤æƒæ–¹å¼ï¼Œé»˜è®¤å‰å¤æƒ
    """
    init_gm()

    symbol = normalize_symbol(code, market=market)
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")

    start_time = start_date + " 09:30:00"
    end_time = end_date + " 15:00:00"

    print(f"ğŸ“¡ ä¸‹è½½ {symbol} åˆ†æ—¶({frequency},å‰å¤æƒ): {start_date} ~ {end_date}")

    df = history(
        symbol=symbol,
        frequency=frequency,
        start_time=start_time,
        end_time=end_time,
        fields="eob,open,high,low,close,volume",
        adjust=adjust,
        df=True,
        # âŒ ä¸è®¾ç½® fill_missingï¼Œä¸åŠ åˆ—ã€ä¸æ”¹é¡ºåº
        # fill_missing=None,
    )

    if df is None or df.empty:
        raise RuntimeError(f"{symbol} åˆ†æ—¶åœ¨ {start_date}~{end_date} æ²¡æœ‰æ‹¿åˆ°æ•°æ®")

    os.makedirs(out_dir, exist_ok=True)

    raw_code = symbol.split(".")[-1]
    cn_name = ensure_utf8_filename(get_symbol_cn_name(symbol))
    freq_tag = frequency.replace("s", "S")

    file_name = ensure_utf8_filename(f"{raw_code}_{cn_name}_{freq_tag}_qfq_gm.csv")
    out_path = ensure_utf8_filename(os.path.join(out_dir, file_name))

    # â­ ç›´æ¥è½ç›˜ history è¿”å›çš„ df
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… åˆ†æ—¶å·²ä¿å­˜åˆ°: {out_path}ï¼Œå…± {len(df)} è¡Œ")
    return out_path


def batch_download_equity_from_csv(
    list_csv: str | None = None,
    data_dirs: list[str] | None = None,
    start_date: str = "2005-01-01",
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_equity",
) -> None:
    """
    æ‰¹é‡ä¸‹è½½ / è¡¥å……è‚¡ç¥¨æ—¥çº¿æ•°æ®ï¼ˆä¸¤ç§æ¥æºäºŒé€‰ä¸€ï¼‰ï¼š

    1ï¼‰è€æ–¹å¼ï¼šé€šè¿‡ config é‡Œçš„åˆ—è¡¨ CSVï¼ˆlist_csvï¼‰
        - CSV ç¤ºä¾‹ï¼š
            code,name,market
            600519,è´µå·èŒ…å°,SH
            000300,æ²ªæ·±300,SH
        - èµ°è€é€»è¾‘ï¼Œæ–¹ä¾¿å…¼å®¹ä¹‹å‰è„šæœ¬

    2ï¼‰æ–°æ–¹å¼ï¼šé€šè¿‡ data_dirs é‡Œå·²ç»å­˜åœ¨çš„ CSV æ–‡ä»¶åæå– code
        - ä¾‹å¦‚ ./data/gm_equity/600519_è´µå·èŒ…å°_D_gm.csv
               ./data/gm_equity_intraday/600519_è´µå·èŒ…å°_1m_gm_raw.csv
        - ç»Ÿä¸€æŠ½å–å‡º 600519 åšå¢é‡æ›´æ–°
    """
    init_gm()

    codes: list[str] = []

    # === æ–°æ–¹å¼ï¼šä¼˜å…ˆä½¿ç”¨ data_dirs ===
    if data_dirs:
        codes = collect_codes_from_dirs(data_dirs)
        if not codes:
            print("âš ï¸ data_dirs ä¸­æœªæ‰¾åˆ°ä»»ä½• CSV æˆ–æ— æ³•æå–ä»£ç ")
    # === æ—§æ–¹å¼ï¼šé€€å› list_csv ===
    elif list_csv:
        df_list = pd.read_csv(list_csv)
        for _, row in df_list.iterrows():
            raw_code = str(row.get("code", "")).strip()
            if not raw_code or raw_code.lower() == "nan":
                continue
            codes.append(raw_code)
        codes = sorted(set(codes))
    else:
        print("âš ï¸ æ—¢æ²¡æœ‰ä¼  data_dirsï¼Œä¹Ÿæ²¡æœ‰ä¼  list_csvï¼Œä¸çŸ¥é“ä»å“ªé‡Œå–æ ‡çš„åˆ—è¡¨")
        return

    if not codes:
        print("âš ï¸ æ²¡æœ‰ä»»ä½•æ ‡çš„éœ€è¦ä¸‹è½½ / æ›´æ–°ï¼Œç»“æŸ")
        return

    print(f"ğŸ“ƒ å¾…å¤„ç†æ ‡çš„æ•°é‡: {len(codes)}")
    print("  " + ", ".join(codes))

    for i, code in enumerate(codes, start=1):
        print(f"\n==== [Equity {i}/{len(codes)}] å¤„ç† {code} ====")
        try:
            # è¿™é‡Œå‡å®šä½ å·²ç»å®ç°äº† update_daily_equityï¼š
            # - å¦‚æœå·²æœ‰å¯¹åº”æ—¥çº¿æ–‡ä»¶ï¼šåªè¡¥æœ€åä¸€å¤©ä¹‹åçš„æ•°æ®
            # - å¦‚æœæ²¡æœ‰ï¼šé€€åŒ–ä¸º download_daily_equity å…¨é‡ä¸‹è½½
            update_daily_equity(
                code=code,
                start_date=start_date,
                end_date=end_date,
                out_dir=out_dir,
                market=None,
            )
        except Exception as e:
            print(f"âŒ {code} æ—¥çº¿è¡¥å……å¤±è´¥: {e}")


def update_intraday_equity(
    code: str,
    frequency: str = "1m",
    out_dir: str = "./data/gm_equity_intraday",
    market: Optional[str] = None,
    end_date: Optional[str] = None,
) -> str:
    """
    åœ¨å·²æœ‰â€œåŸå§‹ gm åˆ†æ—¶ CSVâ€åŸºç¡€ä¸Šè¡¥å……æœ€æ–°æ•°æ®ã€‚
    - æ–‡ä»¶æ ¼å¼ï¼šhistory(df=True) ç›´æ¥ to_csvï¼Œæœ‰ eob, open, high, low, close, volume ç­‰ã€‚
    - æ–‡ä»¶å‘½åï¼š600519_è´µå·èŒ…å°_1m_gm_raw.csv è¿™ç§ã€‚
    - è‹¥æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™é€€åŒ–ä¸ºä¸€æ¬¡å®Œæ•´ä¸‹è½½ï¼ˆè°ƒç”¨ download_intraday_equityï¼‰ã€‚
    """
    init_gm()

    symbol = normalize_symbol(code, market=market)

    today = datetime.now().date()
    if end_date is None:
        end_d = today - timedelta(days=1)  # æ˜é‡‘ï¼šåˆ†æ—¶ä¸å«å½“å¤©
    else:
        end_d = datetime.strptime(end_date, "%Y-%m-%d").date()
        end_d = min(end_d, today - timedelta(days=1))

    out_dir_path = Path(out_dir)
    out_dir_path.mkdir(parents=True, exist_ok=True)

    raw_code = symbol.split(".")[-1]

    # æ‰¾ç°æœ‰åˆ†æ—¶æ–‡ä»¶ï¼š600519_*_1m_gm_raw.csv
    candidates = sorted(out_dir_path.glob(f"{raw_code}_*_{frequency}_gm_raw.csv"))
    if not candidates:
        print(f"â„¹ï¸ æœªæ‰¾åˆ° {raw_code} {frequency} ç°æœ‰åˆ†æ—¶æ–‡ä»¶ï¼Œæ”¹ä¸ºå®Œæ•´ä¸‹è½½")
        # æ³¨æ„ï¼šè¿™é‡Œ start_date å— 180 æ—¥é™åˆ¶ï¼Œåªèƒ½ä» end_d å¾€å‰æœ€å¤š 180 å¤©
        start_d = end_d - timedelta(days=180 - 1)
        return download_intraday_equity(
            code=code,
            frequency=frequency,
            start_date=start_d.strftime("%Y-%m-%d"),
            end_date=end_d.strftime("%Y-%m-%d"),
            out_dir=out_dir,
            market=market,
        )

    out_path = candidates[0]
    df_old = pd.read_csv(out_path)
    if "eob" not in df_old.columns:
        raise RuntimeError(f"{out_path} ç¼ºå°‘ eob åˆ—ï¼Œæ— æ³•åšåˆ†æ—¶å¢é‡æ›´æ–°")

    last_dt = pd.to_datetime(df_old["eob"]).max()
    last_date = last_dt.date()

    # æ–°æ•°æ®ä»â€œæœ€åä¸€å¤©çš„ä¸‹ä¸€å¤©â€å¼€å§‹
    new_start_date = last_date + timedelta(days=1)

    # æ˜é‡‘æƒé™ï¼šend_d å¾€å‰æ•° 180 ä¸ªè‡ªç„¶æ—¥
    gm_min_start = end_d - timedelta(days=180 - 1)
    real_start = max(new_start_date, gm_min_start)

    if real_start > end_d:
        print(f"âœ… {symbol} {frequency} åˆ†æ—¶å·²æ›´æ–°è‡³ {last_date}ï¼Œæ— éœ€è¡¥å……")
        return str(out_path)

    start_time = real_start.strftime("%Y-%m-%d") + " 09:30:00"
    end_time = end_d.strftime("%Y-%m-%d") + " 15:00:00"

    print(f"ğŸ“¡ è¡¥å……ä¸‹è½½ {symbol} {frequency} åˆ†æ—¶: {real_start} ~ {end_d}")

    df_new = history(
        symbol=symbol,
        frequency=frequency,
        start_time=start_time,
        end_time=end_time,
        df=True,
        fill_missing="last",
    )

    if df_new is None or df_new.empty:
        print(f"âš ï¸ {symbol} æ²¡æœ‰æ–°å¢ {frequency} åˆ†æ—¶æ•°æ®")
        return str(out_path)

    # å¯¹é½æ—§æ–‡ä»¶çš„åˆ—é¡ºåºï¼Œé¿å…åˆ—ä¸ä¸€è‡´
    missing_cols = [c for c in df_old.columns if c not in df_new.columns]
    for c in missing_cols:
        df_new[c] = np.nan
    df_new = df_new[df_old.columns]

    df_new.to_csv(out_path, mode="a", index=False, header=False, encoding="utf-8-sig")
    print(f"âœ… {symbol} {frequency} åˆ†æ—¶å·²è¡¥å…… {len(df_new)} æ¡ï¼Œæ–‡ä»¶: {out_path}")
    return str(out_path)


def batch_download_equity_from_csv(
    list_csv: str | None = None,
    data_dirs: list[str] | None = None,
    start_date: str = "2005-01-01",
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_equity",
) -> None:
    """
    æ‰¹é‡ä¸‹è½½ / è¡¥å……è‚¡ç¥¨æ—¥çº¿æ•°æ®ï¼š

    ä¸¤ç§æ¨¡å¼ï¼ˆäºŒé€‰ä¸€ï¼‰ï¼š

    1ï¼‰æ—§æ¨¡å¼ï¼šlist_csv
        - ä»åˆ—è¡¨ CSV è¯»å–è‚¡ç¥¨æ± ï¼ˆcode,name,marketï¼‰
        - è°ƒç”¨ update_daily_equityï¼ˆåœ¨ out_dir é‡Œæ‰¾ / è¡¥ / ä¸‹ï¼‰

    2ï¼‰æ–°æ¨¡å¼ï¼šdata_dirs
        - ä»è‹¥å¹²ä¸ªç›®å½•ä¸­éå†å·²æœ‰ CSV æ–‡ä»¶ï¼ˆå¦‚ 000001_å¹³å®‰é“¶è¡Œ_D_qfq_gm.csvï¼‰
        - é’ˆå¯¹â€œæ¯ä¸€ä¸ªæ–‡ä»¶â€è°ƒç”¨ update_daily_equity_file
        - åœ¨â€œè¯¥æ–‡ä»¶åŸè·¯å¾„â€å°¾éƒ¨è¿½åŠ æ–°æ•°æ®ï¼ˆä¸è¦†ç›–æ—§å†…å®¹ï¼‰
    """
    init_gm()

    # ========= æ–°æ¨¡å¼ï¼šæŒ‰ç›®å½•é‡Œçš„ CSV æ–‡ä»¶å°±åœ°è¡¥å…… =========
    if data_dirs:
        csv_files: list[Path] = []

        for d in data_dirs:
            p = Path(d)
            if not p.exists():
                print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {p}")
                continue
            if not p.is_dir():
                print(f"âš ï¸ ä¸æ˜¯ç›®å½•ï¼Œè·³è¿‡: {p}")
                continue

            # åªå¤„ç†æ—¥çº¿æ–‡ä»¶ï¼šçº¦å®šåŒ…å« "_D_"ï¼ˆä¾‹å¦‚ 600941_ä¸­å›½ç§»åŠ¨_D_qfq_gm.csvï¼‰
            for fp in p.glob("*.csv"):
                if "_D_" not in fp.name:
                    # åˆ†é’Ÿçº¿ã€æœŸè´§ç­‰ç•™ç»™å…¶ä»–è„šæœ¬ï¼ˆä¾‹å¦‚ batch_update_intraday_from_csvï¼‰
                    continue
                csv_files.append(fp)

        if not csv_files:
            print("âš ï¸ åœ¨ data_dirs ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ—¥çº¿ CSVï¼ˆåŒ…å« '_D_' çš„æ–‡ä»¶åï¼‰ï¼Œç»“æŸ")
            return

        print(f"ğŸ“ƒ éœ€è¦å¢é‡æ›´æ–°çš„æ—¥çº¿æ–‡ä»¶æ•°é‡: {len(csv_files)}")
        for i, csv_path in enumerate(sorted(csv_files), start=1):
            print(f"\n==== [Equity FILE {i}/{len(csv_files)}] {csv_path} ====")
            try:
                update_daily_equity_file(
                    csv_path=csv_path,
                    start_date=start_date,
                    end_date=end_date,
                    market=None,   # å¦‚éœ€åŒºåˆ†å¸‚åœºï¼Œå¯ä»¥åä»æ–‡ä»¶åé‡ŒåŠ è§„åˆ™
                )
            except Exception as e:
                print(f"âŒ æ›´æ–° {csv_path.name} å¤±è´¥: {e}")
        return

  # ========= æ—§æ¨¡å¼ï¼šé€šè¿‡åˆ—è¡¨ CSV è¡¥å…… / ä¸‹è½½ =========
    if not list_csv:
        print("âš ï¸ æ—¢æ²¡æœ‰ä¼  data_dirsï¼Œä¹Ÿæ²¡æœ‰ä¼  list_csvï¼Œä¸çŸ¥é“ä»å“ªé‡Œå–æ ‡çš„åˆ—è¡¨")
        return

    # â­ ç”¨ dtype=strï¼Œé¿å… 000001 â†’ 1
    df_list = pd.read_csv(list_csv, dtype=str)

    records: list[tuple[str, str | None]] = []

    for _, row in df_list.iterrows():
        raw_code = (row.get("code") or "").strip()
        if not raw_code or raw_code.lower() == "nan":
            continue

        # â­ è¡¥é½ 6 ä½ï¼Œä¿è¯ 000001 ä¸è¢«åƒæ‰
        code = raw_code.zfill(6)

        raw_mkt = (row.get("market") or "").strip().upper()
        market = raw_mkt if raw_mkt else None

        records.append((code, market))

    if not records:
        print("âš ï¸ åˆ—è¡¨ CSV ä¸­æ²¡æœ‰æœ‰æ•ˆä»£ç ")
        return

    # å»é‡
    records = sorted(set(records), key=lambda x: (x[0], x[1] or ""))

    print(f"ğŸ“ƒ å¾…å¤„ç†æ ‡çš„æ•°é‡: {len(records)}")
    print("  " + ", ".join([r[0] for r in records]))

    for i, (code, market) in enumerate(records, start=1):
        print(f"\n==== [Equity {i}/{len(records)}] å¤„ç† {code} (market={market or '-'}) ===")
        try:
            update_daily_equity(
                code=code,
                start_date=start_date,
                end_date=end_date,
                out_dir=out_dir,
                market=market,   # â­ æŠŠ CSV é‡Œçš„ market ä¼ è¿›æ¥
            )
        except Exception as e:
            print(f"âŒ {code} æ—¥çº¿è¡¥å……å¤±è´¥: {e}")


# ========= æœŸè´§ æ—¥çº¿ =========

def download_future_kline(
    symbol: str,
    start_date: str = "2015-01-01",
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_futures",
) -> str:
    """
    ä¸‹è½½å•ä¸ªè‚¡æŒ‡æœŸè´§åˆçº¦çš„æ—¥çº¿æ•°æ®

    å‚æ•°ï¼š
        symbol: ä¾‹å¦‚ "CFFEX.IF2501" / "CFFEX.IC2503"
    """
    init_gm()

    symbol = symbol.strip().upper()
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")

    start_time = start_date + " 09:00:00"
    end_time = end_date + " 15:15:00"

    print(f"ğŸ“¡ ä¸‹è½½æœŸè´§ {symbol} æ—¥çº¿: {start_date} ~ {end_date}")

    df = history(
        symbol=symbol,
        frequency="1d",
        start_time=start_time,
        end_time=end_time,
        fields="eob,open,high,low,close,volume",
        df=True,
        fill_missing="last",
    )

    if df is None or df.empty:
        raise RuntimeError(f"{symbol} åœ¨ {start_date}~{end_date} æ²¡æœ‰æ‹¿åˆ°æ•°æ®")

    df = df.copy()
    df["date"] = pd.to_datetime(df["eob"]).dt.strftime("%Y-%m-%d")
    df = df[["date", "open", "high", "low", "close", "volume"]]
    df = df.sort_values("date")

    os.makedirs(out_dir, exist_ok=True)

    code = symbol.split(".")[-1]            # IF2501
    cn_name = ensure_utf8_filename(get_symbol_cn_name(symbol))    # æ²ªæ·±300æŒ‡æ•°æœŸè´§ ç­‰
    file_name = ensure_utf8_filename(f"{code}_{cn_name}_FUT_D_gm.csv")
    out_path = ensure_utf8_filename(os.path.join(out_dir, file_name))

    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ä¿å­˜åˆ°: {out_path}, å…± {len(df)} è¡Œ")
    return out_path


def batch_download_futures_from_csv(
    list_csv: str,
    start_date: str = "2015-01-01",
    end_date: Optional[str] = None,
    out_dir: str = "./data/gm_futures",
) -> None:
    """
    ä» CSV æ‰¹é‡ä¸‹è½½æœŸè´§æ—¥çº¿

    CSV ç¤ºä¾‹ï¼š
        code,name
        CFFEX.IF2501,æ²ªæ·±300IF2501
        CFFEX.IC2503,ä¸­è¯500IC2503
        CFFEX.IM2503,ä¸­è¯1000IM2503
        CFFEX.IH2503,ä¸Šè¯50IH2503
    """
    init_gm()

    df_list = pd.read_csv(list_csv)
    total = len(df_list)
    print(f"ğŸ“ƒ Futures å¾…ä¸‹è½½åˆçº¦æ•°é‡: {total}")

    for i, row in df_list.iterrows():
        raw_code = str(row.get("code", "")).strip().upper()
        if not raw_code or raw_code.lower() == "nan":
            continue

        print(f"\n==== [FUT {i+1}/{total}] ä¸‹è½½æœŸè´§ {raw_code} ====")
        try:
            download_future_kline(
                symbol=raw_code,
                start_date=start_date,
                end_date=end_date,
                out_dir=out_dir,
            )
        except Exception as e:
            print(f"âŒ {raw_code} ä¸‹è½½å¤±è´¥: {e}")

def extract_code_from_filename(path: Path) -> str:
    """
    ä»ä¿å­˜å¥½çš„ CSV æ–‡ä»¶åé‡Œæå–ä»£ç éƒ¨åˆ†ã€‚

    çº¦å®šå‘½åè§„åˆ™ç±»ä¼¼ï¼š
        600519_è´µå·èŒ…å°_D_gm.csv
        600941_ä¸­å›½ç§»åŠ¨_D_qfq_gm.csv
        600519_è´µå·èŒ…å°_1m_gm_raw.csv

    åˆ™ç»Ÿä¸€å–æ–‡ä»¶åç¬¬ä¸€ä¸ª "_" ä¹‹å‰çš„éƒ¨åˆ†ä½œä¸º codeï¼š
        -> 600519 / 600941
    """
    stem = path.stem  # ä¸å«æ‰©å±•å
    if "_" not in stem:
        return stem.strip()
    return stem.split("_", 1)[0].strip()


def collect_codes_from_dirs(data_dirs: list[str]) -> list[str]:
    """
    ä»ä¸€ç»„ç›®å½•ä¸­æ”¶é›†æ‰€æœ‰ CSV æ–‡ä»¶ï¼Œå¹¶æ ¹æ®æ–‡ä»¶åæå– codeï¼Œå»é‡åè¿”å›æ’åºå¥½çš„åˆ—è¡¨ã€‚
    """
    codes: set[str] = set()

    for d in data_dirs:
        p = Path(d)
        if not p.exists():
            print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {p}")
            continue
        if not p.is_dir():
            print(f"âš ï¸ ä¸æ˜¯ç›®å½•ï¼Œè·³è¿‡: {p}")
            continue

        for csv_path in p.glob("*.csv"):
            code = extract_code_from_filename(csv_path)
            if code:
                codes.add(code)

    return sorted(codes)


# ========= ç¤ºä¾‹å…¥å£ =========

if __name__ == "__main__":
    # ä½ å¯ä»¥åªå¼€å…¶ä¸­ä¸€ç±»ï¼Œä¹Ÿå¯ä»¥ä¸¤ç±»ä¸€èµ·è·‘

    # === 1. æ‰¹é‡ä¸‹è½½è‚¡ç¥¨ / æŒ‡æ•°æ—¥çº¿ ===
        equity_list_csv = "./config/gm_HS300_daily_list.csv"   # è‡ªå·±ç»´æŠ¤è¿™ä¸ªåˆ—è¡¨
        if os.path.exists(equity_list_csv):
            batch_download_equity_from_csv(
                list_csv=equity_list_csv,
                start_date="1990-01-01",
                end_date=None,                # None = æˆªæ­¢åˆ°ä»Šå¤©
                out_dir="./data/gm_HS300_equity",
            )
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° equity åˆ—è¡¨æ–‡ä»¶: {equity_list_csv}ï¼Œè·³è¿‡è‚¡ç¥¨/æŒ‡æ•°ä¸‹è½½")

    # === 2. æ‰¹é‡ä¸‹è½½è‚¡æŒ‡æœŸè´§æ—¥çº¿ ===
        futures_list_csv = "./config/gm_futures_list.csv"
        if os.path.exists(futures_list_csv):
            batch_download_futures_from_csv(
                list_csv=futures_list_csv,
                start_date="1990-01-01",
                end_date=None,
                out_dir="./data/gm_futures",
            )
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° futures åˆ—è¡¨æ–‡ä»¶: {futures_list_csv}ï¼Œè·³è¿‡æœŸè´§ä¸‹è½½")
    

    # === 3. ä»ç°æœ‰æ•°æ®ç›®å½•è‡ªåŠ¨è¯†åˆ«æ ‡çš„ï¼Œå¹¶è¡¥å……æ—¥çº¿ ===
data_dirs = [
    "./data/gm_159599ETF_equity",     # æ¯”å¦‚ä½ ä»¥åæ–°å¢çš„ç›®å½•
]

'''batch_download_equity_from_csv(
    data_dirs=data_dirs,
    start_date="1990-01-01",
    end_date=None,   # None = æˆªæ­¢åˆ°ä»Šå¤©
    # out_dir å‚æ•°åœ¨ data_dirs æ¨¡å¼ä¸‹ä¸ä¼šç”¨åˆ°ï¼Œå¯ä»¥ç•™ç€å…¼å®¹æ—§è°ƒç”¨
)'''
